# BLIP Image Captioning Web App

This project is an AI-powered image captioning application built using the **Salesforce BLIP (Bootstrapping Language-Image Pretraining)** model.

Users can upload an image and receive an automatically generated natural language caption.

---

## Live Demo

- Deployed on Hugging Face Spaces using Gradio.
- Link: https://milesmaloka-ai-image-captioning.hf.space/
---

## Model Used

- Salesforce BLIP Image Captioning (Base)
- Transformer-based Vision-Language model

---

## Tech Stack

- Python
- PyTorch
- Hugging Face Transformers
- Gradio
- Pillow

---

## How It Works

1. User uploads an image.
2. The image is processed using the BLIP processor.
3. The BLIP model generates a caption.
4. The caption is decoded and displayed in the web interface.

---

## Project Structure
